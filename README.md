# SpeechSync- A Lip Reading Project

[screen-capture (1).webm](https://github.com/A-dvika/SpeechSync/assets/115079077/4e20b398-869b-48e1-a8fe-79bf163c1459)

## 🎙️ Lip Reading with LipNet Architecture 📹

This lip reading project harnesses the power of the LipNet architecture, a cutting-edge deep learning model tailored for lip reading tasks. LipNet amalgamates convolutional and recurrent neural networks to decode speech information from visual cues captured in video sequences.

### Architecture Overview 🏗️
Checkout the Paper -https://arxiv.org/pdf/1611.01599.pdf
The architecture of LipNet comprises several layers, including convolutional layers for robust feature extraction from video frames, bidirectional recurrent layers to capture temporal dependencies in lip movements, and fully connected layers for precise classification. This intricate design empowers LipNet to proficiently learn the intricate relationship between lip movements and spoken words.

### Demo 🚀

This project showcases a Streamlit web application that demonstrates the lip reading capabilities. Users can effortlessly select any video from a dropdown menu, and the chosen video undergoes real-time processing using LipNet. As the video unfolds, the lip movements are meticulously analyzed, and the corresponding speech is decoded. The resulting sentences are dynamically displayed to the user, providing an interactive and immersive experience.

### Potential Applications 💡

This project underscores the versatile applications of LipNet in various real-world scenarios. From enhancing accessibility for individuals with hearing impairments to revolutionizing human-computer interaction through innovative lip-based input methods, LipNet exhibits immense potential in reshaping how we perceive and interact with spoken language.

